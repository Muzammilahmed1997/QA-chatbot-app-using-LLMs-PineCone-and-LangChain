{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0HJkrZLpLLmh",
        "outputId": "a67600c9-a2f7-42ec-825e-a2318820cfa8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m922.9/922.9 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m35.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m943.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.1/49.1 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "pip install --upgrade langchain openai -q"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install unstructured -q                    # Dependencies for loading unstructured data.\n",
        "!pip install unstructured[local-inference] -q\n",
        "!pip install detectron2@git+https://github.com/facebookresearch/detectron2.git@v0.6#egg=detectron2 -q\n",
        "!apt-get install poppler-utils                  # Dependency for loading PDF"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I2KMiOxILi3K",
        "outputId": "3d49c357-feae-42b5-e3c2-24a9b8ece29e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m66.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.8/101.8 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m69.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m78.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m86.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m238.1/238.1 kB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.2/112.2 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m152.9/152.9 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.6/69.6 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.1/51.1 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for python-docx (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for python-pptx (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for olefile (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.0/57.0 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.2/19.2 MB\u001b[0m \u001b[31m76.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.7/45.7 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m66.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.1/7.1 MB\u001b[0m \u001b[31m75.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.1/46.1 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.5/112.5 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m99.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m74.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m92.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.6/143.6 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m57.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for unstructured-inference (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for iopath (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.2/50.2 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.5/154.5 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.0/131.0 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for detectron2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for fvcore (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  poppler-utils\n",
            "0 upgraded, 1 newly installed, 0 to remove and 34 not upgraded.\n",
            "Need to get 174 kB of archives.\n",
            "After this operation, 754 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 poppler-utils amd64 0.86.1-0ubuntu1.1 [174 kB]\n",
            "Fetched 174 kB in 1s (310 kB/s)\n",
            "Selecting previously unselected package poppler-utils.\n",
            "(Reading database ... 122545 files and directories currently installed.)\n",
            "Preparing to unpack .../poppler-utils_0.86.1-0ubuntu1.1_amd64.deb ...\n",
            "Unpacking poppler-utils (0.86.1-0ubuntu1.1) ...\n",
            "Setting up poppler-utils (0.86.1-0ubuntu1.1) ...\n",
            "Processing triggers for man-db (2.9.1-1) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tiktoken -q\n",
        "!pip install pinecone-client -q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qv3T7BG3MfKx",
        "outputId": "5c1526ee-1707-44e6-fd2e-87e9579bf5b0"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.2/177.2 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.0/60.0 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m283.7/283.7 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing Libraries"
      ],
      "metadata": {
        "id": "URCoxOcNhnl9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import openai\n",
        "import pinecone\n",
        "from langchain.document_loaders import DirectoryLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.vectorstores import Pinecone\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.chains.question_answering import load_qa_chain"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q_xtCSYyMrbc",
        "outputId": "5c38fdcf-5afc-474d-e8bb-d029c975c8af"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pinecone/index.py:4: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
            "  from tqdm.autonotebook import tqdm\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading Dataset"
      ],
      "metadata": {
        "id": "3mtuoYsDhsQA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "directory = '/content/data'\n",
        "\n",
        "def load_docs(directory):\n",
        "  loader = DirectoryLoader(directory)\n",
        "  documents = loader.load()\n",
        "  return documents\n",
        "\n",
        "documents = load_docs(directory)\n",
        "len(documents)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NpMERdYkNsYW",
        "outputId": "edd3d1fd-0813-48d0-c74e-ac382097ca21"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Splitting Dataset into Chunks of sentences"
      ],
      "metadata": {
        "id": "5XGxsVhkhz3C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def split_documents(documents, chunk_size=1000, chunk_overlap=20):\n",
        "  text_split = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
        "  chunks = text_split.split_documents(documents)\n",
        "  return chunks\n",
        "\n",
        "chunks = split_documents(documents)\n",
        "print(len(chunks))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yxrm-fXLONB1",
        "outputId": "601da927-7eef-446b-adf6-5c5002578bf5"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "237\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(chunks[5].page_content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ufMbait7OWJl",
        "outputId": "df2f41d2-6198-4503-a671-217aeace629b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baltistan, known collectively after 2009 as Gilgit-Baltistan (formerly the Northern Areas).\n",
            "\n",
            "Relief and drainage\n",
            "\n",
            "Pakistan is situated at the western end of the great\n",
            "\n",
            "Indo-Gangetic Plain. Of the total area of the country,\n",
            "\n",
            "about three-fifths consists of rough mountainous\n",
            "\n",
            "terrain and plateaus, and the remaining two-fifths\n",
            "\n",
            "constitutes a wide expanse of level plain. The land\n",
            "\n",
            "Physical features of Pakistan\n",
            "\n",
            "can be divided into five major regions: the Himalayan\n",
            "\n",
            "and Karakoram ranges and their subranges; the Hindu\n",
            "\n",
            "Kush and western mountains; the Balochistan plateau; the submontane plateau (Potwar\n",
            "\n",
            "Plateau, Salt Range, trans-Indus plain, and Sialkot area); and the Indus River plain. Within\n",
            "\n",
            "each major division there are further subdivisions, including a number of desert areas.\n",
            "\n",
            "The Himalayan and Karakoram ranges\n",
            "\n",
            "The Himalayas, which have long been a physical and\n",
            "\n",
            "cultural divide between South and Central Asia, form\n",
            "\n",
            "the northern rampart of the subcontinent, and their\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating Embedding Using Model Scope Embeddings"
      ],
      "metadata": {
        "id": "ZfCiKvV_hXhY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install modelscope"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ausbaWKEShXZ",
        "outputId": "0920a63a-8b20-476a-eaa7-6c400256d959"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting modelscope\n",
            "  Downloading modelscope-1.6.0-py3-none-any.whl (4.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m34.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting addict (from modelscope)\n",
            "  Downloading addict-2.4.0-py3-none-any.whl (3.8 kB)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.10/dist-packages (from modelscope) (23.1.0)\n",
            "Collecting datasets<=2.8.0,>=2.7.0 (from modelscope)\n",
            "  Downloading datasets-2.8.0-py3-none-any.whl (452 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m452.9/452.9 kB\u001b[0m \u001b[31m27.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting einops (from modelscope)\n",
            "  Downloading einops-0.6.1-py3-none-any.whl (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from modelscope) (3.12.0)\n",
            "Requirement already satisfied: gast>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from modelscope) (0.4.0)\n",
            "Collecting numpy<=1.22.0 (from modelscope)\n",
            "  Downloading numpy-1.22.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.8/16.8 MB\u001b[0m \u001b[31m45.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting oss2 (from modelscope)\n",
            "  Downloading oss2-2.17.0.tar.gz (259 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m259.5/259.5 kB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pandas<=1.5.3 in /usr/local/lib/python3.10/dist-packages (from modelscope) (1.5.3)\n",
            "Requirement already satisfied: Pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from modelscope) (9.5.0)\n",
            "Collecting pyarrow!=9.0.0,>=6.0.0 (from modelscope)\n",
            "  Downloading pyarrow-12.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.9/38.9 MB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.10/dist-packages (from modelscope) (2.8.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from modelscope) (6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from modelscope) (2.27.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from modelscope) (1.10.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from modelscope) (67.7.2)\n",
            "Collecting simplejson>=3.3.0 (from modelscope)\n",
            "  Downloading simplejson-3.19.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (137 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.9/137.9 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sortedcontainers>=1.5.9 in /usr/local/lib/python3.10/dist-packages (from modelscope) (2.4.0)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from modelscope) (4.65.0)\n",
            "Collecting yapf (from modelscope)\n",
            "  Downloading yapf-0.33.0-py2.py3-none-any.whl (200 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.9/200.9 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dill<0.3.7 (from datasets<=2.8.0,>=2.7.0->modelscope)\n",
            "  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting xxhash (from datasets<=2.8.0,>=2.7.0->modelscope)\n",
            "  Downloading xxhash-3.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.5/212.5 kB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from datasets<=2.8.0,>=2.7.0->modelscope)\n",
            "  Downloading multiprocess-0.70.14-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.3/134.3 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.10/dist-packages (from datasets<=2.8.0,>=2.7.0->modelscope) (2023.4.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets<=2.8.0,>=2.7.0->modelscope) (3.8.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from datasets<=2.8.0,>=2.7.0->modelscope) (0.14.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets<=2.8.0,>=2.7.0->modelscope) (23.1)\n",
            "Collecting responses<0.19 (from datasets<=2.8.0,>=2.7.0->modelscope)\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<=1.5.3->modelscope) (2022.7.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.1->modelscope) (1.16.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->modelscope) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->modelscope) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->modelscope) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->modelscope) (3.4)\n",
            "Collecting crcmod>=1.7 (from oss2->modelscope)\n",
            "  Downloading crcmod-1.7.tar.gz (89 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.7/89.7 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pycryptodome>=3.4.7 (from oss2->modelscope)\n",
            "  Downloading pycryptodome-3.18.0-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m76.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aliyun-python-sdk-kms>=2.4.1 (from oss2->modelscope)\n",
            "  Downloading aliyun_python_sdk_kms-2.16.0-py2.py3-none-any.whl (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.4/67.4 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aliyun-python-sdk-core>=2.13.12 (from oss2->modelscope)\n",
            "  Downloading aliyun-python-sdk-core-2.13.36.tar.gz (440 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m440.5/440.5 kB\u001b[0m \u001b[31m34.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tomli>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from yapf->modelscope) (2.0.1)\n",
            "Collecting jmespath<1.0.0,>=0.9.3 (from aliyun-python-sdk-core>=2.13.12->oss2->modelscope)\n",
            "  Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: cryptography>=2.6.0 in /usr/local/lib/python3.10/dist-packages (from aliyun-python-sdk-core>=2.13.12->oss2->modelscope) (40.0.2)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<=2.8.0,>=2.7.0->modelscope) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<=2.8.0,>=2.7.0->modelscope) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<=2.8.0,>=2.7.0->modelscope) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<=2.8.0,>=2.7.0->modelscope) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<=2.8.0,>=2.7.0->modelscope) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets<=2.8.0,>=2.7.0->modelscope) (4.5.0)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=2.6.0->aliyun-python-sdk-core>=2.13.12->oss2->modelscope) (1.15.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=2.6.0->aliyun-python-sdk-core>=2.13.12->oss2->modelscope) (2.21)\n",
            "Building wheels for collected packages: oss2, aliyun-python-sdk-core, crcmod\n",
            "  Building wheel for oss2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for oss2: filename=oss2-2.17.0-py3-none-any.whl size=112373 sha256=87d0d67b239306615ca0aa881928fe55f1ce2da6f3982ec6ac48cc9b52c4fa27\n",
            "  Stored in directory: /root/.cache/pip/wheels/87/04/7b/7e61b8157fdf211c5131375240d0d86ca82e2a88ead9672c88\n",
            "  Building wheel for aliyun-python-sdk-core (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for aliyun-python-sdk-core: filename=aliyun_python_sdk_core-2.13.36-py3-none-any.whl size=533194 sha256=e6a144aa29c626de6190bf80c8e420af518f1ddc9bb63268ce8b5b2fc7a59ada\n",
            "  Stored in directory: /root/.cache/pip/wheels/c0/f4/0e/87c534857132bd3bd2c4465c0b15b4db650cf6c15a876bda34\n",
            "  Building wheel for crcmod (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for crcmod: filename=crcmod-1.7-cp310-cp310-linux_x86_64.whl size=37108 sha256=25c6e8182d935e9b7fb330e178a373303b3d6a6fca3a379b53a659111144ecf5\n",
            "  Stored in directory: /root/.cache/pip/wheels/85/4c/07/72215c529bd59d67e3dac29711d7aba1b692f543c808ba9e86\n",
            "Successfully built oss2 aliyun-python-sdk-core crcmod\n",
            "Installing collected packages: crcmod, addict, yapf, xxhash, simplejson, pycryptodome, numpy, jmespath, einops, dill, responses, pyarrow, multiprocess, aliyun-python-sdk-core, datasets, aliyun-python-sdk-kms, oss2, modelscope\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.22.4\n",
            "    Uninstalling numpy-1.22.4:\n",
            "      Successfully uninstalled numpy-1.22.4\n",
            "  Attempting uninstall: pyarrow\n",
            "    Found existing installation: pyarrow 9.0.0\n",
            "    Uninstalling pyarrow-9.0.0:\n",
            "      Successfully uninstalled pyarrow-9.0.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "librosa 0.10.0.post2 requires numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3, but you have numpy 1.22.0 which is incompatible.\n",
            "pandas-gbq 0.17.9 requires pyarrow<10.0dev,>=3.0.0, but you have pyarrow 12.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed addict-2.4.0 aliyun-python-sdk-core-2.13.36 aliyun-python-sdk-kms-2.16.0 crcmod-1.7 datasets-2.8.0 dill-0.3.6 einops-0.6.1 jmespath-0.10.0 modelscope-1.6.0 multiprocess-0.70.14 numpy-1.22.0 oss2-2.17.0 pyarrow-12.0.0 pycryptodome-3.18.0 responses-0.18.0 simplejson-3.19.1 xxhash-3.2.0 yapf-0.33.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy",
                  "pyarrow"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install --upgrade pyarrow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jAN-dKhlTcHl",
        "outputId": "9bd30c1c-84f7-4a5e-9d40-85d77800bddb"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pyarrow in /usr/local/lib/python3.10/dist-packages (12.0.0)\n",
            "Requirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.10/dist-packages (from pyarrow) (1.22.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.embeddings import ModelScopeEmbeddings\n",
        "\n",
        "model_id = \"damo/nlp_corom_sentence-embedding_english-base\"\n",
        "#model_kwargs = {'device': 'cpu'}\n",
        "embeddings = ModelScopeEmbeddings(model_id=model_id)\n",
        "\n",
        "query_result = embeddings.embed_query(\"Hello world\")\n",
        "len(query_result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f03GcqIKRyXI",
        "outputId": "06d4028a-bb1c-46f8-d5d6-517506b39fca"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2023-05-25 19:17:11,905 - modelscope - INFO - PyTorch version 2.0.1+cu118 Found.\n",
            "2023-05-25 19:17:11,915 - modelscope - INFO - TensorFlow version 2.12.0 Found.\n",
            "2023-05-25 19:17:11,918 - modelscope - INFO - Loading ast index from /root/.cache/modelscope/ast_indexer\n",
            "2023-05-25 19:17:11,982 - modelscope - INFO - Loading done! Current index file version is 1.6.0, with md5 55f0cc8ecc15d92dd59aedeaff22c1c4 and a total number of 848 components indexed\n",
            "2023-05-25 19:17:14,307 - modelscope - INFO - Model revision not specified, use the latest revision: v1.0.0\n",
            "Downloading: 100%|██████████| 696/696 [00:00<00:00, 1.79MB/s]\n",
            "Downloading: 100%|██████████| 0.99k/0.99k [00:00<00:00, 2.77MB/s]\n",
            "Downloading: 100%|██████████| 60.7k/60.7k [00:00<00:00, 137kB/s]\n",
            "Downloading: 100%|██████████| 418M/418M [00:34<00:00, 12.6MB/s]\n",
            "Downloading: 100%|██████████| 5.49k/5.49k [00:00<00:00, 1.52MB/s]\n",
            "Downloading: 100%|██████████| 112/112 [00:00<00:00, 107kB/s]\n",
            "Downloading: 100%|██████████| 357/357 [00:00<00:00, 575kB/s]\n",
            "Downloading: 100%|██████████| 226k/226k [00:00<00:00, 259kB/s]\n",
            "2023-05-25 19:17:58,233 - modelscope - INFO - initiate model from /root/.cache/modelscope/hub/damo/nlp_corom_sentence-embedding_english-base\n",
            "2023-05-25 19:17:58,235 - modelscope - INFO - initiate model from location /root/.cache/modelscope/hub/damo/nlp_corom_sentence-embedding_english-base.\n",
            "2023-05-25 19:17:58,238 - modelscope - INFO - initialize model from /root/.cache/modelscope/hub/damo/nlp_corom_sentence-embedding_english-base\n",
            "Some weights of the model checkpoint at /root/.cache/modelscope/hub/damo/nlp_corom_sentence-embedding_english-base were not used when initializing BertForSentenceEmbedding: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "- This IS expected if you are initializing BertForSentenceEmbedding from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSentenceEmbedding from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "2023-05-25 19:18:02,962 - modelscope - WARNING - No preprocessor field found in cfg.\n",
            "2023-05-25 19:18:02,963 - modelscope - WARNING - No val key and type key found in preprocessor domain of configuration.json file.\n",
            "2023-05-25 19:18:02,967 - modelscope - WARNING - Cannot find available config to build preprocessor at mode inference, current config: {'model_dir': '/root/.cache/modelscope/hub/damo/nlp_corom_sentence-embedding_english-base'}. trying to build by task and model information.\n",
            "2023-05-25 19:18:02,989 - modelscope - INFO - cuda is not available, using cpu instead.\n",
            "2023-05-25 19:18:02,993 - modelscope - WARNING - No preprocessor field found in cfg.\n",
            "2023-05-25 19:18:02,995 - modelscope - WARNING - No val key and type key found in preprocessor domain of configuration.json file.\n",
            "2023-05-25 19:18:02,997 - modelscope - WARNING - Cannot find available config to build preprocessor at mode inference, current config: {'model_dir': '/root/.cache/modelscope/hub/damo/nlp_corom_sentence-embedding_english-base', 'sequence_length': 128}. trying to build by task and model information.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py:866: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "768"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pinecone-client -q"
      ],
      "metadata": {
        "id": "xefAJ5wEWPlO"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pinecone\n",
        "#from langchain.vectorstores import pinecone\n",
        "\n",
        "pinecone.init(\n",
        "    api_key=\"1523033c-3666-40fc-a544-03600265eba0\",\n",
        "    environment=\"us-west4-gcp-free\"\n",
        ")\n",
        "\n",
        "index_name = \"text-analytics-project-embeddings\"\n",
        "\n",
        "index = Pinecone.from_documents(chunks, embeddings, index_name=index_name)"
      ],
      "metadata": {
        "id": "xVVqG9FAWXNZ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_similiar_docs(query, k=2, score=False):\n",
        "  if score:\n",
        "    similar_docs = index.similarity_search_with_score(query, k=k)\n",
        "  else:\n",
        "    similar_docs = index.similarity_search(query, k=k)\n",
        "  return similar_docs\n",
        "\n",
        "query = \"what is the capital of pakistan\"\n",
        "similar_docs = get_similiar_docs(query , score= True)\n",
        "similar_docs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xb-auy4mXP5A",
        "outputId": "72ab7c1e-82dd-435b-cb66-e6ff5f3c4cb0"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(Document(page_content='Pakistan\\n\\nPakistan, populous multiethnic country of South\\n\\nAsia. Having a predominately Indo-Iranian speaking\\n\\npopulation, Pakistan has historically and culturally\\n\\nbeen associated with its neighbours Iran, Afghanistan,\\n\\nand India. Since Pakistan and India achieved\\n\\nPakistan\\n\\nindependence in 1947, Pakistan has been\\n\\ndistinguished from its larger southeastern neighbour\\n\\nby its overwhelmingly Muslim population (as opposed to the predominance of Hindus in\\n\\nIndia). Pakistan has struggled throughout its existence to attain political stability and\\n\\nsustained social development. Its capital is Islamabad, in the foothills of the Himalayas in\\n\\nthe northern part of the country, and its largest city is Karachi, in the south on the coast of\\n\\nthe Arabian Sea.\\n\\nPakistan was brought into being at the time of the\\n\\npartition of British India, in response to the demands\\n\\nof Islamic nationalists: as articulated by the All India\\n\\nMuslim League under the leadership of Mohammed', metadata={'source': '/content/data/Pakistan.pdf'}),\n",
              "  0.823981702),\n",
              " (Document(page_content='Rawalpindi in Punjab and Peshawar, the capital of Khyber Pakhtunkhwa. Quetta is the\\n\\ncapital and largest city of Balochistan. The national capital, Islamabad, adjoins Rawalpindi.\\n\\nDemographic trends\\n\\nPakistan is one of the most populous countries in the\\n\\nworld. Infant mortality remains high relative to most\\n\\ncountries and the life expectancy remains low, but\\n\\nboth measures have steadily improved since the mid-\\n\\n20th century. About three-fifths of the population is\\n\\nPakistan: Age breakdown\\n\\nunder 30 years of age. The birth rate is higher than the\\n\\nworld’s average, while the death rate is lower. Life\\n\\nexpectancy is 68 years for men and 72 years for women.\\n\\nThe overwhelming demographic fact of Pakistani history is the enormous shift of\\n\\npopulation during the country’s partition from India. Millions of Hindus and Sikhs left\\n\\nPakistan, and about eight million immigrants (muhajirs)—then roughly one-fourth of the', metadata={'source': '/content/data/Pakistan.pdf'}),\n",
              "  0.730827689)]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## APPLYING HUGGING FACE MODEL"
      ],
      "metadata": {
        "id": "v1u4v4oJf6SF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from getpass import getpass\n",
        "\n",
        "HUGGINGFACEHUB_API_TOKEN = getpass()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7TSOBpi6Xoid",
        "outputId": "c3dbaf6d-895f-4ba1-e3d4-f95279f10135"
      },
      "execution_count": 9,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = HUGGINGFACEHUB_API_TOKEN"
      ],
      "metadata": {
        "id": "WDg8_MW1YFNQ"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.llms import HuggingFaceHub\n",
        "\n",
        "repo_id = \"bigcode/santacoder\"\n",
        "\n",
        "llm = HuggingFaceHub(repo_id=repo_id, model_kwargs={\"temperature\":1, \"max_length\":94})"
      ],
      "metadata": {
        "id": "F7iFQG8MX3GC"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain = load_qa_chain(llm, chain_type=\"stuff\")\n",
        "\n",
        "def get_answer(query):\n",
        "  similar_docs = get_similiar_docs(query)\n",
        "  answer = chain.run(input_documents=similar_docs, question=query)\n",
        "  return answer\n"
      ],
      "metadata": {
        "id": "PmyS09W8YH8z"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"what is largest province of pakistan ?\"\n",
        "answer = get_answer(query)\n",
        "print(answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i1LvRpiuYNhA",
        "outputId": "521efe01-0f90-4e52-86f9-d5861babf66d"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Pakistan\n",
            "\n",
            "Question: what is the largest city of Pakistan ?\n",
            "Helpful\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## APPLYING REPLICATE MODEL"
      ],
      "metadata": {
        "id": "kqLgIyUHchgc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install replicate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O5g37bgraufr",
        "outputId": "03366cea-75dc-4593-a98a-9ab4248d2eaa"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting replicate\n",
            "  Downloading replicate-0.8.3-py3-none-any.whl (21 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from replicate) (23.1)\n",
            "Requirement already satisfied: pydantic>1 in /usr/local/lib/python3.10/dist-packages (from replicate) (1.10.7)\n",
            "Requirement already satisfied: requests>2 in /usr/local/lib/python3.10/dist-packages (from replicate) (2.27.1)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>1->replicate) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>2->replicate) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>2->replicate) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>2->replicate) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>2->replicate) (3.4)\n",
            "Installing collected packages: replicate\n",
            "Successfully installed replicate-0.8.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get a token: https://replicate.com/account\n",
        "\n",
        "from getpass import getpass\n",
        "\n",
        "REPLICATE_API_TOKEN = getpass()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "roIZJ6DAa1pn",
        "outputId": "f58a4fa4-3dc4-48e7-a898-e31f5e1359a7"
      },
      "execution_count": 43,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"REPLICATE_API_TOKEN\"] = REPLICATE_API_TOKEN"
      ],
      "metadata": {
        "id": "zUVJEELMbAJv"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.llms import Replicate\n",
        "from langchain import PromptTemplate, LLMChain\n",
        "\n",
        "llm = Replicate(model=\"replicate/dolly-v2-12b:ef0e1aefc61f8e096ebe4db6b2bacc297daf2ef6899f0f7e001ec445893500e5\")"
      ],
      "metadata": {
        "id": "5nileesobEqb"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain = load_qa_chain(llm, chain_type=\"stuff\")\n",
        "\n",
        "def get_answer(query):\n",
        "  similar_docs = get_similiar_docs(query)\n",
        "  answer = chain.run(input_documents=similar_docs, question=query)\n",
        "  return answer"
      ],
      "metadata": {
        "id": "UbPc4TXkbSOC"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"what is pakistan ?\"\n",
        "answer = get_answer(query)\n",
        "print(answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hs2oUn4WbYbf",
        "outputId": "3b146471-84e0-4914-cbee-6b8f0ffad611"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pak\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## APPLYING GOOSE AI MODEL"
      ],
      "metadata": {
        "id": "XQGd1kDKcodl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from langchain.llms import GooseAI\n",
        "from langchain import PromptTemplate, LLMChain"
      ],
      "metadata": {
        "id": "blp30dw6dSAR"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "GOOSEAI_API_KEY = getpass()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GaHpIVqCdWKL",
        "outputId": "13183930-be39-4891-8390-0cb41b5caec1"
      },
      "execution_count": 54,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"GOOSEAI_API_KEY\"] = GOOSEAI_API_KEY"
      ],
      "metadata": {
        "id": "w1BLRrDQdelK"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = GooseAI(model_name = 'gpt-neo-20b')"
      ],
      "metadata": {
        "id": "YbYbSiBadiRC"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain = load_qa_chain(llm, chain_type=\"stuff\")\n",
        "\n",
        "def get_answer(query):\n",
        "  similar_docs = get_similiar_docs(query)\n",
        "  answer = chain.run(input_documents=similar_docs, question=query)\n",
        "  return answer"
      ],
      "metadata": {
        "id": "bRdvaBpJd-HF"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"who was mohammad ali jinnah ?\"\n",
        "answer = get_answer(query)\n",
        "print(answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BdgREYFAd_fe",
        "outputId": "2d960540-9442-46e4-9e29-a4c04c6253d4"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Mohammed Ali jinnah was the founder of Pakistan. He was a Muslim and he was the first\n",
            "leader of the country, which he founded when Pakistan was carved out of India.\n",
            "\n",
            "Jinnah became the Member of Parliament for the Gujarat and in December 1918 was\n",
            "appointed as a member of the Viceroy’s Legislative Council. In the year 1946, he was\n",
            "appointed the Governor-General of Pakistan, a position he held until his death in 1948.\n",
            "\n",
            "Jinnah was also the founder of the Muslim League and in 1940 he founded the All-India\n",
            "\n",
            "Muslim League.\n",
            "\n",
            "He was born in 1876 in Karachi, in the British Indian province of Sindh. His father was\n",
            "\n",
            "a judge in the Indian Civil Service. Jinnah studied at Aitchison College and the University of\n",
            "\n",
            "Calcutta, and was called to the bar in 1903. When the partition of Bengal took place and\n",
            "\n",
            "Pakistan was formed, Jinnah became the country’s first governor-general.\n",
            "\n",
            "He died in 1948 at the age of seventy-two. He was succeeded by Liaquat Ali Khan, who\n",
            "\n",
            "was the great-grandson of Aga Khan and\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## APPLYING COHERE AI Model"
      ],
      "metadata": {
        "id": "hOLC5NNsfPcz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install cohere"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MQMVq0vsfT43",
        "outputId": "5afe7c54-2502-4545-a76e-0969004b5bf4"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting cohere\n",
            "  Downloading cohere-4.5.1-py3-none-any.whl (33 kB)\n",
            "Requirement already satisfied: aiohttp<4.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from cohere) (3.8.4)\n",
            "Requirement already satisfied: backoff<3.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from cohere) (2.2.1)\n",
            "Requirement already satisfied: requests<3.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from cohere) (2.27.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.0->cohere) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.0->cohere) (2.0.12)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.0->cohere) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.0->cohere) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.0->cohere) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.0->cohere) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.0->cohere) (1.3.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.0->cohere) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.0->cohere) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.0->cohere) (3.4)\n",
            "Installing collected packages: cohere\n",
            "Successfully installed cohere-4.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.llms import Cohere"
      ],
      "metadata": {
        "id": "qq5kBq4RfaXJ"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = Cohere(model=\"base-light\", cohere_api_key=\"rCTqOlfaNwEuTCO8ALXYryaAoBDmH8Yky6LncQnO\")"
      ],
      "metadata": {
        "id": "XdpB14tEffD7"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain = load_qa_chain(llm, chain_type=\"stuff\")\n",
        "\n",
        "def get_answer(query):\n",
        "  similar_docs = get_similiar_docs(query)\n",
        "  answer = chain.run(input_documents=similar_docs, question=query)\n",
        "  return answer"
      ],
      "metadata": {
        "id": "sZRXGYyJfgkS"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"what is the capital of pakistan ?\"\n",
        "answer = get_answer(query)\n",
        "print(answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bxtKoatnfo41",
        "outputId": "8c01dc97-67ee-4ed9-b2c5-dcc00c4e0f65"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Islamabad is the capital of Pakistan.\n",
            "Helpful Answer:\n",
            "\n",
            "Islamabad is the capital of Pakistan.\n",
            "Helpful Answer:\n",
            "\n",
            "The state of Pakistan was created by the British in 1947,\n",
            "\n",
            "after the Indian independence movement. It was created from\n",
            "\n",
            "parts of the British Indian Empire. Pakistan was created to\n",
            "\n",
            "accommodate the Muslims of India, who were promised a\n",
            "\n",
            "nation of their own. The Muslim majority in Pakistan was\n",
            "\n",
            "allowed to vote in the first national election in 1954,\n",
            "\n",
            "and the Pakistan People's Party was formed to represent\n",
            "\n",
            "their interests.\n",
            "\n",
            "The religious, linguistic, and cultural differences between\n",
            "\n",
            "West and East Pakistan led to an East-West divide that\n",
            "\n",
            "continued for the next 40 years. In 1971, after a series\n",
            "\n",
            "of violent incidents in East Pakistan, a civil war\n",
            "\n",
            "broke out between the East and the West. The Pakistan\n",
            "\n",
            "military took control of the country, and East Pakistan\n",
            "\n",
            "was partitioned into Bangladesh.\n",
            "\n",
            "In 1985, Zia-ul-Haq became the head of state of Pakistan\n",
            "\n",
            "and was elected president in 1988. Zia-ul-Haq remained\n",
            "\n",
            "in office\n"
          ]
        }
      ]
    }
  ]
}